{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPu3aIPaDFlA"
   },
   "source": [
    "# Exercise: Follow Up on Advertising Data Set; Cross Validation and Parameter Optimization\n",
    "\n",
    "We have discussed the importance of cross validation (CV) and parameter optimization \n",
    "for evaluation and model tuning.\n",
    "\n",
    "The goal of this exercise is to familiarize yourself with the corresponding utilities provided \n",
    "in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNdpS3fREHIW"
   },
   "source": [
    "Answer below questions.\n",
    "The code snippeds already contained in the notebook will provide you with hints.\n",
    "\n",
    "- **For each question, give the answer by adding it to this cell.**\n",
    "- **Submit your answers through this [form](https://forms.gle/8aXAk1oMB4Kn4tDb8).**\n",
    "\n",
    "\n",
    "## Questions\n",
    "### Advertising Follow Up\n",
    "1. Why did we decide to scale the inputs?\n",
    "1. We observed a positive coefficient for TV but a negative for TV^2.\n",
    "   What does this mean?\n",
    "1. Using one of the models, describe and interpret the result of spending\n",
    "   - no money\n",
    "   - and an ever increasing amount of money\n",
    "   \n",
    "   on sales. Is this behaviour reasonable?\n",
    "\n",
    "### Parameter Optimization I\n",
    "1. What is the optimal degree you obtain after performing a cross-validated grid search?\n",
    "1. What coefficients do you obtain after performing a cross-validated grid search?\n",
    "\n",
    "### Parameter Optimization II\n",
    "1. What does the decision region plot tell you?\n",
    "1. What is the optimal parameter setting you obtain for the `DecisionTreeClassifier` after performing a cross-validated grid search?\n",
    "1. How do the decision regions differ between the default and the cross-validated model?\n",
    "1. Bonus: How does the decision region differ when using a `RandomForestClassifier`? Any ideas why it looks different?\n",
    "\n",
    "## Answers\n",
    "### Parameter Optimization I\n",
    "1. TBA\n",
    "1. TBA\n",
    "1. TBA\n",
    "\n",
    "### Parameter Optimization II\n",
    "1. TBA\n",
    "1. TBA\n",
    "1. TBA\n",
    "1. TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Optimization I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given data\n",
    "x = np.array([-1.76128841, -1.63158024, -1.53752642, -1.51748534, -1.29819298,\n",
    "       -1.27003308, -1.09259419, -1.08694708, -0.99817854, -0.85544266,\n",
    "       -0.82514381, -0.78351684, -0.75095511, -0.73085807, -0.70816434,\n",
    "       -0.62894466, -0.62728794, -0.55284538, -0.43152993, -0.40782298,\n",
    "       -0.34069515, -0.33191116, -0.30757416, -0.29667884, -0.29459477,\n",
    "       -0.27654895, -0.26519531, -0.24571102, -0.07627239, -0.06786294,\n",
    "       -0.02525961,  0.0073467 ,  0.04168935,  0.07794048,  0.1262055 ,\n",
    "        0.12731035,  0.18027203,  0.20525908,  0.41224051,  0.44409404,\n",
    "        0.4515781 ,  0.49581181,  0.5239045 ,  0.53760383,  0.72520306,\n",
    "        0.73931895,  0.78587674,  0.87787588,  0.88977353,  0.8978213 ,\n",
    "        0.91619883,  0.95198162,  1.3053632 ,  1.39772718,  1.46523663,\n",
    "        1.50182737,  1.57355665,  1.77664007,  1.92305679,  1.94223914]).reshape((-1, 1))\n",
    "\n",
    "y = np.array([12.52002464, 10.19783868,  9.30437687,  9.37500655,  7.94905528,\n",
    "        3.81413555,  5.74304708,  3.4380946 ,  2.76820418,  3.46115356,\n",
    "        1.73343419,  4.08605565,  3.12061054,  3.3085446 ,  1.19416302,\n",
    "        2.51087828,  2.41009238,  1.27328361,  1.09926486,  1.96093725,\n",
    "        1.24933231,  1.7335095 ,  1.49818064,  1.27902629,  1.90791481,\n",
    "        1.75213245,  1.20290468,  0.87234103,  1.02297036,  1.04514318,\n",
    "        1.04662249,  1.00726388,  0.93594893,  1.00951318,  0.93474991,\n",
    "        0.98445663,  0.59479965,  0.74519815,  0.26032586,  0.38746046,\n",
    "        0.68397116,  0.95859012, -0.21909301, -0.19769223, -0.09708284,\n",
    "        0.88095766,  1.435611  ,  0.40325439,  1.45902219, -0.22903704,\n",
    "       -0.51728928, -0.46341346, -2.54312459,  0.6652953 , -2.40960325,\n",
    "       -1.31908844, -1.49930838, -3.07503961, -8.16209329, -0.7027068 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the degree parameter in PolynomialFeatures\n",
    "model = Pipeline([('polynomial_features', PolynomialFeatures()), \n",
    "                  ('regression', LinearRegression(fit_intercept=False))])\n",
    "# by evaluating the grid\n",
    "param_grid = {'polynomial_features__degree': [1, 2, 3, 4, 5]}\n",
    "# using a cross-validated search\n",
    "\n",
    "grid_search_cv = GridSearchCV(#TODO, \n",
    "                              #TODO, \n",
    "                              cv=5, \n",
    "                              refit=True)\n",
    "# some missing pieces are marked as #TODO, others you have to fill in on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_cv.best_estimator_\n",
    "best_model.named_steps.regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Optimization II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given data\n",
    "X, y = make_moons(n_samples=200, noise=0.3, random_state=123)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split for demo purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit for demo purposes\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "fig, ax = plt.subplots()\n",
    "plot_decision_regions(X_test, y_test, model, ax=ax)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to above\n",
    "# use GridSearchCV to optimize the model parameters max_depth and min_samples_split\n",
    "grid_search_cv = GridSearchCV(#TODO, \n",
    "                              #TODO, \n",
    "                              cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve best parameter combination as\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a new model on the training data using the best parameters from above\n",
    "best_model = grid_search_cv.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
